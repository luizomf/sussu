# sussu(rro): CLI educacional com OpenAI Whisper

> Ferramenta de linha de comando focada em educaÃ§Ã£o e IA offline.
> Usa o poder do Whisper da OpenAI para transcrever Ã¡udios e vÃ­deos de forma simples.

Ao rodar este projeto, uma das primeiras coisas que vocÃª vai querer fazer Ã© usar o comando `whisper` para fazer a transcriÃ§Ã£o inicial de algum vÃ­deo ou Ã¡udio. Essa transcriÃ§Ã£o Ã© um Ã³timo jeito de ver na prÃ¡tica como o **Whisper** trabalha e o que esperar dos resultados.

- [RepositÃ³rio oficial do `whisper`](https://github.com/openai/whisper)

Por isso, vamos comeÃ§ar pela **instalaÃ§Ã£o** do projeto, o que vai disponibilizar os comandos `sussu` e `whisper` no terminal.

## InstalaÃ§Ã£o do `sussu`

Se vocÃª encontrar alguma dificuldade com o ambiente, recomendo meu tutorial completo:

- [Ambiente Python Moderno 2025: UV, Ruff, Pyright, pyproject.toml e VS Code](https://www.youtube.com/watch?v=HuAc85cLRx0)

Este projeto utiliza o **Python 3.11.9** por questÃµes de compatibilidade com o **Whisper**. Evite alterar essa versÃ£o se nÃ£o souber o que estÃ¡ fazendo, pois **eu jÃ¡ testei tudo para vocÃª**.

AlÃ©m disso, este projeto usa o [`uv`](https://docs.astral.sh/uv/) para o gerenciamento geral (pacotes, versÃ£o do Python, etc.).

Para instalar tudo, basta rodar o comando:

```sh
uv sync  # Ã© sÃ³ isso mesmo ğŸ˜…
```

`uv sync` Ã© suficiente para:

- Baixar e instalar o `python 3.11.9`
- Criar o ambiente virtual em `.venv`
- Instalar os pacotes necessÃ¡rios
- Buildar o `whisper` e o `sussu`

---

## `ffmpeg`

VocÃª tambÃ©m precisarÃ¡ ter o **`ffmpeg`** instalado. Ele Ã© um software de cÃ³digo aberto com vÃ¡rias ferramentas e bibliotecas para trabalhar com arquivos multimÃ­dia, especialmente Ã¡udio e vÃ­deo. Embora o `whisper` foque na transcriÃ§Ã£o de Ã¡udio, o `ffmpeg` Ã© quem permite que vocÃª transcreva seus vÃ­deos diretamente, sem precisar convertÃª-los para Ã¡udio antes.

Para instalar o `ffmpeg` no seu sistema, vocÃª pode usar um dos comandos abaixo. Eles foram retirados diretamente do [repositÃ³rio oficial do `whisper`](https://github.com/openai/whisper):

```bash
# No Ubuntu ou Debian
sudo apt update && sudo apt install ffmpeg

# No Arch Linux
sudo pacman -S ffmpeg

# No macOS com Homebrew (https://brew.sh/)
brew install ffmpeg

# No Windows com Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# No Windows usando Scoop (https://scoop.sh/)
scoop install ffmpeg

# Adicional: No Windows usando winget (https://winstall.app/apps/Gyan.FFmpeg)
winget install --id=Gyan.FFmpeg -e
```

**ObservaÃ§Ã£o:** Dos comandos listados, os Ãºnicos que testei e aprovei (âœ…) foram os para **macOS** e **Ubuntu**.

---

## Rodando pela Primeira Vez

Para verificar se tudo foi instalado corretamente, vocÃª tem duas opÃ§Ãµes: **ativar o ambiente virtual** ou usar o comando **`uv run`**. Sugiro que vocÃª teste com `whisper -h`. Esse comando deve exibir a ajuda completa do `whisper`, indicando que ele estÃ¡ funcionando. Veja os exemplos:

```bash
uv run whisper -h
# Ou, se vocÃª jÃ¡ ativou o ambiente virtual
whisper -h
```

**ObservaÃ§Ã£o:** Editores de cÃ³digo como **VS Code** ou **Zed** podem ativar o ambiente virtual automaticamente ao abrir um novo terminal, desde que estejam configurados corretamente. Se for o seu caso, basta fechar e abrir o terminal novamente para que as mudanÃ§as faÃ§am efeito.

---

## `whisper -h`: Entendendo Alguns Argumentos Importantes

Ao digitar `whisper -h` ou `whisper --help`, vocÃª pode se surpreender com a quantidade de argumentos disponÃ­veis. Mas nÃ£o se preocupe! VocÃª nÃ£o precisa saber o que cada um deles faz. Na verdade, a maioria dos argumentos jÃ¡ vem com valores padrÃ£o que funcionam perfeitamente. No entanto, se vocÃª quiser personalizar um pouco o comportamento da ferramenta, vamos analisar alguns dos mais importantes.

O `whisper` utiliza a biblioteca `argparse` do Python para gerar essa documentaÃ§Ã£o de ajuda (`help`) completa e bem organizada. Se vocÃª tiver interesse em aprender mais sobre como criar interfaces de linha de comando profissionais com Python, confira meu vÃ­deo:

- [Python e argparse: Do Zero a uma CLI Profissional (Projeto Real na PrÃ¡tica)](https://www.youtube.com/watch?v=Ad6934NXn4A)

---

### Argumentos Essenciais do `whisper`

Vamos comeÃ§ar com os argumentos que vocÃª usarÃ¡ com mais frequÃªncia:

**`audio`**: Este Ã© o **argumento posicional** principal. Ele representa o caminho completo (localizaÃ§Ã£o) do arquivo de Ã¡udio ou vÃ­deo que vocÃª quer transcrever.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4
```

No exemplo acima, vocÃª notou que especificamos apenas o caminho do arquivo de vÃ­deo. Nas prÃ³ximas seÃ§Ãµes, vou detalhar as opÃ§Ãµes que mais utilizo para personalizar a transcriÃ§Ã£o.

---

**`--model MODEL`**: Este argumento serve para **definir qual modelo serÃ¡ usado na transcriÃ§Ã£o** do seu Ã¡udio ou vÃ­deo. Ele Ã© opcional, e o valor padrÃ£o Ã© `turbo`. O modelo `turbo` Ã© excelente: rÃ¡pido e multilÃ­ngue, mas requer cerca de **6GB de VRAM** para rodar.

Talvez vocÃª queira usar outros modelos que exigem mais ou menos recursos do seu hardware, ou que possuem mais ou menos parÃ¢metros (como `base`, `small`, `medium`, etc.).

Aqui estÃ£o os modelos disponÃ­veis e seus requisitos aproximados de VRAM:

- **`tiny`**: 39M parÃ¢metros, `tiny.en` e `tiny`, VRAM ~1 GB
- **`base`**: 74M parÃ¢metros, `base.en` e `base`, VRAM ~1 GB
- **`small`**: 244M parÃ¢metros, `small.en` e `small`, VRAM ~2 GB
- **`medium`**: 769M parÃ¢metros, `medium.en` e `medium`, VRAM ~5 GB
- **`large`**: 1550M parÃ¢metros, `large`, `large-v2` e `large-v3`, VRAM ~10 GB
- **`turbo`**: 809M parÃ¢metros, `turbo`, VRAM ~6 GB

**VRAM** Ã© um tipo de memÃ³ria RAM especializada que as placas de vÃ­deo (GPUs) usam. Mas nÃ£o se preocupe se vocÃª nÃ£o tiver uma placa de vÃ­deo dedicada! Se seu computador compartilha a RAM com a GPU, o que acontece em Macs com chips Apple Silicon (M1, M2, M3 e posteriores), por exemplo, vocÃª conseguirÃ¡ usar os modelos do Whisper normalmente.

Nesses casos, o que realmente limita Ã© a **quantidade total de memÃ³ria RAM disponÃ­vel no seu sistema**. Por exemplo: se vocÃª tem apenas 8GB de RAM, o ideal Ã© testar os modelos `tiny`, `base` ou `small`.

A partir do modelo `medium`, Ã© bem provÃ¡vel que vocÃª perceba uma **queda drÃ¡stica no desempenho geral da sua mÃ¡quina**, jÃ¡ que a memÃ³ria serÃ¡ completamente consumida.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2
```

---

**`--device DEVICE`**: Este argumento Ã© para vocÃª que possui uma **placa de vÃ­deo NVIDIA com drivers CUDA** e uma versÃ£o compatÃ­vel com o PyTorch. Se for o seu caso, vale a pena usar `--device cuda` para aproveitar o processamento da GPU. Caso contrÃ¡rio, nÃ£o se preocupe em alterar esta opÃ§Ã£o, o padrÃ£o Ã© `cpu` (processamento pela CPU) e funcionarÃ¡ perfeitamente.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2 --device cpu
```

---

**`--output_dir` ou `-o`**: Define o **caminho da pasta onde as transcriÃ§Ãµes serÃ£o salvas**. Por padrÃ£o, os arquivos serÃ£o salvos na raiz do projeto (`.`).

**`--output_format` ou `-f`**: Permite que vocÃª escolha o **formato da transcriÃ§Ã£o ou legenda** gerada. As opÃ§Ãµes disponÃ­veis sÃ£o: `txt`, `vtt`, `srt`, `tsv`, `json` e `all` (que gera todos os formatos). O padrÃ£o Ã© `all`.


**Exemplo:**

O arquivo de saÃ­da serÃ¡ `srt` (SubRip) na pasta indicada em `-o`. Essa pasta serÃ¡ criada caso nÃ£o exista.

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo -o caminho/da/pasta_de_saida -f srt
```

---

**`--task`**: Com este argumento, vocÃª pode escolher entre **transcrever o Ã¡udio** no idioma original ou **traduzir para o inglÃªs**. As opÃ§Ãµes sÃ£o `transcribe` (o padrÃ£o, que transcreve no idioma falado no Ã¡udio) ou `translate` (que traduz o conteÃºdo para o inglÃªs).

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo --task transcribe
```

---

**`--language`**: Este argumento permite que vocÃª **especifique o idioma falado no Ã¡udio ou vÃ­deo**. Existem muitas opÃ§Ãµes de idiomas disponÃ­veis. Se vocÃª nÃ£o informar esse argumento, o `whisper` Ã© inteligente o suficiente para detectar automaticamente o idioma do conteÃºdo.

Forma curta (language code):

```python
["af", "am", "ar", "as", "az", "ba", "be", "bg", "bn", "bo", "br", "bs", "ca",
"cs", "cy", "da", "de", "el", "en", "es", "et", "eu", "fa", "fi", "fo", "fr",
"gl", "gu", "ha", "haw", "he", "hi", "hr", "ht", "hu", "hy", "id", "is", "it",
"ja", "jw", "ka", "kk", "km", "kn", "ko", "la", "lb", "ln", "lo", "lt", "lv",
"mg", "mi", "mk", "ml", "mn", "mr", "ms", "mt", "my", "ne", "nl", "nn", "no",
"oc", "pa", "pl", "ps", "pt", "ro", "ru", "sa", "sd", "si", "sk", "sl", "sn",
"so", "sq", "sr", "su", "sv", "sw", "ta", "te", "tg", "th", "tk", "tl", "tr",
"tt", "uk", "ur", "uz", "vi", "yi", "yo", "yue", "", "zh"]
```

- Exemplo para portuguÃªs do Brasil: `--language pt`

Forma longa (language name):

```python
["Afrikaans", "Albanian", "Amharic", "Arabic", "Armenian", "Assamese",
"Azerbaijani", "Bashkir", "Basque", "Belarusian", "Bengali", "Bosnian",
"Breton", "Bulgarian", "Burmese", "Cantonese", "Castilian", "Catalan",
"Chinese", "Croatian", "Czech", "Danish", "Dutch", "English", "Estonian",
"Faroese", "Finnish", "Flemish", "French", "Galician", "Georgian", "German",
"Greek", "Gujarati", "Haitian", "Haitian Creole", "Hausa", "Hawaiian", "Hebrew",
"Hindi", "Hungarian", "Icelandic", "Indonesian", "Italian", "Japanese",
"Javanese", "Kannada", "Kazakh", "Khmer", "Korean", "Lao", "Latin", "Latvian",
"Letzeburgesch", "Lingala", "Lithuanian", "Luxembourgish", "Macedonian",
"Malagasy", "Malay", "Malayalam", "Maltese", "Mandarin", "Maori", "Marathi",
"Moldavian", "Moldovan", "Mongolian", "Myanmar", "Nepali", "Norwegian",
"Nynorsk", "Occitan", "Panjabi", "Pashto", "Persian", "Polish", "Portuguese",
"Punjabi", "Pushto", "Romanian", "Russian", "Sanskrit", "Serbian", "Shona",
"Sindhi", "Sinhala", "Sinhalese", "Slovak", "Slovenian", "Somali", "Spanish",
"Sundanese", "Swahili", "Swedish", "Tagalog", "Tajik", "Tamil", "Tatar",
"Telugu", "Thai", "Tibetan", "Turkish","Turkmen", "Ukrainian", "Urdu", "Uzbek",
"Valencian", "Vietnamese", "Welsh", "Yiddish", "Yoruba"]
```

- Exemplo para portuguÃªs do Brasil: `--language Portuguese`

Se precisar de um dicionÃ¡rio completo com todos os idiomas e seus cÃ³digos, ele estÃ¡ disponÃ­vel em `whisper.tokenizer.LANGUAGES` dentro do cÃ³digo do `whisper`.


**Exemplo:**

```bash
# Para o comando ficar menor, vou manter tudo padrÃ£o
# model turbo (padrÃ£o)
# task transcribe (padrÃ£o)
# etc...
# Idioma falado no vÃ­deo "PortuguÃªs"
whisper /caminho/do/seu/arquivo.mp4 --language pt
```


---

**`--temperature`:** controla a "criatividade" do modelo. Vai de `0.0` a `1.0`. Quanto mais alto, mais liberdade o modelo tem pra decidir os prÃ³ximos tokens. Esse parÃ¢metro interage com `--beam_size`, `--patience` e `--best_of`.

**`--beam_size`:** nÃºmero de hipÃ³teses que o modelo mantÃ©m em paralelo. Pensa como se ele testasse vÃ¡rios caminhos ao mesmo tempo e no fim escolhesse o melhor. O padrÃ£o Ã© `5` e **sÃ³ funciona se `--temperature == 0.0`**.

**`--patience`:** fator de tolerÃ¢ncia que faz o modelo continuar explorando novas hipÃ³teses mesmo depois de achar uma aceitÃ¡vel. Requer `--temperature == 0.0` e `--beam_size > 1`.

**`--best_of`:** nÃºmero de amostras diferentes geradas antes de escolher a melhor. Funciona apenas quando `--temperature > 0.0`.

**Cola rÃ¡pida:**

```
- temperature > 0 â†’ usa sampling
  âœ… --best_of 5 (5 amostras)
  ğŸ”´ --beam_size (ignorado)
  ğŸ”´ --patience (ignorado)

- temperature == 0 â†’ usa beam search
  âœ… --beam_size 5 (5 hipÃ³teses)
  âœ… --patience 2 (2 x 5 = 10 hipÃ³teses)
  ğŸ”´ --best_of (ignorado)

- temperature == 0 â†’ greedy
  âœ… --beam_size 1 (1 hipÃ³tese)
  ğŸ”´ --patience (nÃ£o faz diferenÃ§a)
  ğŸ”´ --best_of (ignorado)
```

**Importante:** Quanto maiores os valores de `--beam_size`, `--patience` e `--best_of`, mais lento e "indeciso" o modelo tende a ficar. Isso acontece porque ele precisa gerar mais hipÃ³teses ou amostras e, em seguida, tomar uma decisÃ£o entre elas. FaÃ§a testes rÃ¡pidos para confirmar esse comportamento.

**ObservaÃ§Ã£o sincera:**

Na prÃ¡tica, o modelo vai responder como foi treinado, independente do seu capricho nas configs. Trocar `temperature`, `beam_size`, `patience` e afins pode virar desperdÃ­cio de tempo.

**RecomendaÃ§Ã£o direta:** sÃ³ mexa nessas opÃ§Ãµes se:

- o modelo comeÃ§ar a repetir palavras (loop)
- estiver errando demais em blocos grandes

Se for sÃ³ por causa de uma ou duas palavras... aceita e segue. Ou entÃ£o faz igual eu: **testa tudo por uma semana e conclui que o padrÃ£o jÃ¡ era bom** ğŸ˜…

**Exemplo:**

O arquivo de saÃ­da serÃ¡ `srt` (SubRip) na pasta indicada em `-o`. Essa pasta serÃ¡ criada caso nÃ£o exista.

```bash
# Greedy: Mais rÃ¡pido, mas pode errar mais por considerar apenas uma hipÃ³tese por vez.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 1

# Beam Search: Utiliza 3 hipÃ³teses em paralelo.
# O 'patience' padrÃ£o Ã© 1.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 3

# Sampling: Gera 5 amostras diferentes para escolher a melhor.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.7 --best_of 5
```

**`--temperature_increment_on_fallback`**: Este argumento permite que vocÃª **aumente a temperatura do modelo em casos de falha na transcriÃ§Ã£o**. Se o modelo encontrar dificuldades na temperatura `0.0`, ele farÃ¡ um "fallback" e tentarÃ¡ com a temperatura incrementada. O valor tambÃ©m varia de `0.0` a `1.0`. No entanto, **cuidado: definir `0.0` para este argumento causarÃ¡ um erro `ZeroDivisionError: float division by zero`** (isso pode ser um pequeno "bugzinho" ğŸ«£, mas, de fato, nÃ£o faria muito sentido usar zero aqui, jÃ¡ que o objetivo Ã© justamente *incrementar* a temperatura). O valor padrÃ£o Ã© `0.2`.

---
