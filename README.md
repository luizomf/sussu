# sussu(rro): CLI educacional com OpenAI Whisper

> Ferramenta de linha de comando focada em educa√ß√£o e IA offline.
> Usa o poder do Whisper da OpenAI para transcrever √°udios e v√≠deos de forma simples.

Ao rodar este projeto, uma das primeiras coisas que voc√™ vai querer fazer √© usar o comando `whisper` para fazer a transcri√ß√£o inicial de algum v√≠deo ou √°udio. Essa transcri√ß√£o √© um √≥timo jeito de ver na pr√°tica como o **Whisper** trabalha e o que esperar dos resultados.

- [Reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper)

Por isso, vamos come√ßar pela **instala√ß√£o** do projeto, o que vai disponibilizar os comandos `sussu` e `whisper` no terminal.

## Instala√ß√£o do `sussu`

Se voc√™ encontrar alguma dificuldade com o ambiente, recomendo meu tutorial completo:

- [Ambiente Python Moderno 2025: UV, Ruff, Pyright, pyproject.toml e VS Code](https://www.youtube.com/watch?v=HuAc85cLRx0)

Este projeto utiliza o **Python 3.11.9** por quest√µes de compatibilidade com o **Whisper**. Evite alterar essa vers√£o se n√£o souber o que est√° fazendo, pois **eu j√° testei tudo para voc√™**.

Al√©m disso, este projeto usa o [`uv`](https://docs.astral.sh/uv/) para o gerenciamento geral (pacotes, vers√£o do Python, etc.).

Para instalar tudo, basta rodar o comando:

```sh
uv sync  # √© s√≥ isso mesmo üòÖ
```

`uv sync` √© suficiente para:

- Baixar e instalar o `python 3.11.9`
- Criar o ambiente virtual em `.venv`
- Instalar os pacotes necess√°rios
- Buildar o `whisper` e o `sussu`

---

## `ffmpeg`

Voc√™ tamb√©m precisar√° ter o **`ffmpeg`** instalado. Ele √© um software de c√≥digo aberto com v√°rias ferramentas e bibliotecas para trabalhar com arquivos multim√≠dia, especialmente √°udio e v√≠deo. Embora o `whisper` foque na transcri√ß√£o de √°udio, o `ffmpeg` √© quem permite que voc√™ transcreva seus v√≠deos diretamente, sem precisar convert√™-los para √°udio antes.

Para instalar o `ffmpeg` no seu sistema, voc√™ pode usar um dos comandos abaixo. Eles foram retirados diretamente do [reposit√≥rio oficial do `whisper`](https://github.com/openai/whisper):

```bash
# No Ubuntu ou Debian
sudo apt update && sudo apt install ffmpeg

# No Arch Linux
sudo pacman -S ffmpeg

# No macOS com Homebrew (https://brew.sh/)
brew install ffmpeg

# No Windows com Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# No Windows usando Scoop (https://scoop.sh/)
scoop install ffmpeg

# Adicional: No Windows usando winget (https://winstall.app/apps/Gyan.FFmpeg)
winget install --id=Gyan.FFmpeg -e
```

**Observa√ß√£o:** Dos comandos listados, os √∫nicos que testei e aprovei (‚úÖ) foram os para **macOS** e **Ubuntu**.

---

## Rodando pela Primeira Vez

Para verificar se tudo foi instalado corretamente, voc√™ tem duas op√ß√µes: **ativar o ambiente virtual** ou usar o comando **`uv run`**. Sugiro que voc√™ teste com `whisper -h`. Esse comando deve exibir a ajuda completa do `whisper`, indicando que ele est√° funcionando. Veja os exemplos:

```bash
uv run whisper -h
# Ou, se voc√™ j√° ativou o ambiente virtual
whisper -h
```

**Observa√ß√£o:** Editores de c√≥digo como **VS Code** ou **Zed** podem ativar o ambiente virtual automaticamente ao abrir um novo terminal, desde que estejam configurados corretamente. Se for o seu caso, basta fechar e abrir o terminal novamente para que as mudan√ßas fa√ßam efeito.

---

## `whisper -h`: Entendendo Alguns Argumentos Importantes

Ao digitar `whisper -h` ou `whisper --help`, voc√™ pode se surpreender com a quantidade de argumentos dispon√≠veis. Mas n√£o se preocupe! Voc√™ n√£o precisa saber o que cada um deles faz. Na verdade, a maioria dos argumentos j√° vem com valores padr√£o que funcionam perfeitamente. No entanto, se voc√™ quiser personalizar um pouco o comportamento da ferramenta, vamos analisar alguns dos mais importantes.

O `whisper` utiliza a biblioteca `argparse` do Python para gerar essa documenta√ß√£o de ajuda (`help`) completa e bem organizada. Se voc√™ tiver interesse em aprender mais sobre como criar interfaces de linha de comando profissionais com Python, confira meu v√≠deo:

- [Python e argparse: Do Zero a uma CLI Profissional (Projeto Real na Pr√°tica)](https://www.youtube.com/watch?v=Ad6934NXn4A)

---

### Argumentos Essenciais do `whisper`

Vamos come√ßar com os argumentos que voc√™ usar√° com mais frequ√™ncia:

**`audio`**: Este √© o **argumento posicional** principal. Ele representa o caminho completo (localiza√ß√£o) do arquivo de √°udio ou v√≠deo que voc√™ quer transcrever.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4
```

No exemplo acima, voc√™ notou que especificamos apenas o caminho do arquivo de v√≠deo. Nas pr√≥ximas se√ß√µes, vou detalhar as op√ß√µes que mais utilizo para personalizar a transcri√ß√£o.

---

**`--model MODEL`**: Este argumento serve para **definir qual modelo ser√° usado na transcri√ß√£o** do seu √°udio ou v√≠deo. Ele √© opcional, e o valor padr√£o √© `turbo`. O modelo `turbo` √© excelente: r√°pido e multil√≠ngue, mas requer cerca de **6GB de VRAM** para rodar.

Talvez voc√™ queira usar outros modelos que exigem mais ou menos recursos do seu hardware, ou que possuem mais ou menos par√¢metros (como `base`, `small`, `medium`, etc.).

Aqui est√£o os modelos dispon√≠veis e seus requisitos aproximados de VRAM:

- **`tiny`**: 39M par√¢metros, `tiny.en` e `tiny`, VRAM ~1 GB
- **`base`**: 74M par√¢metros, `base.en` e `base`, VRAM ~1 GB
- **`small`**: 244M par√¢metros, `small.en` e `small`, VRAM ~2 GB
- **`medium`**: 769M par√¢metros, `medium.en` e `medium`, VRAM ~5 GB
- **`large`**: 1550M par√¢metros, `large`, `large-v2` e `large-v3`, VRAM ~10 GB
- **`turbo`**: 809M par√¢metros, `turbo`, VRAM ~6 GB

**VRAM** √© um tipo de mem√≥ria RAM especializada que as placas de v√≠deo (GPUs) usam. Mas n√£o se preocupe se voc√™ n√£o tiver uma placa de v√≠deo dedicada! Se seu computador compartilha a RAM com a GPU, o que acontece em Macs com chips Apple Silicon (M1, M2, M3 e posteriores), por exemplo, voc√™ conseguir√° usar os modelos do Whisper normalmente.

Nesses casos, o que realmente limita √© a **quantidade total de mem√≥ria RAM dispon√≠vel no seu sistema**. Por exemplo: se voc√™ tem apenas 8GB de RAM, o ideal √© testar os modelos `tiny`, `base` ou `small`.

A partir do modelo `medium`, √© bem prov√°vel que voc√™ perceba uma **queda dr√°stica no desempenho geral da sua m√°quina**, j√° que a mem√≥ria ser√° completamente consumida.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2
```

---

**`--device DEVICE`**: Este argumento √© para voc√™ que possui uma **placa de v√≠deo NVIDIA com drivers CUDA** e uma vers√£o compat√≠vel com o PyTorch. Se for o seu caso, vale a pena usar `--device cuda` para aproveitar o processamento da GPU. Caso contr√°rio, n√£o se preocupe em alterar esta op√ß√£o, o padr√£o √© `cpu` (processamento pela CPU) e funcionar√° perfeitamente.

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model large-v2 --device cpu
```

---

**`--output_dir` ou `-o`**: Define o **caminho da pasta onde as transcri√ß√µes ser√£o salvas**. Por padr√£o, os arquivos ser√£o salvos na raiz do projeto (`.`).

**`--output_format` ou `-f`**: Permite que voc√™ escolha o **formato da transcri√ß√£o ou legenda** gerada. As op√ß√µes dispon√≠veis s√£o: `txt`, `vtt`, `srt`, `tsv`, `json` e `all` (que gera todos os formatos). O padr√£o √© `all`.

**Exemplo:**

O arquivo de sa√≠da ser√° `srt` (SubRip) na pasta indicada em `-o`. Essa pasta ser√° criada caso n√£o exista.

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo -o caminho/da/pasta_de_saida -f srt
```

---

**`--task`**: Com este argumento, voc√™ pode escolher entre **transcrever o √°udio** no idioma original ou **traduzir para o ingl√™s**. As op√ß√µes s√£o `transcribe` (o padr√£o, que transcreve no idioma falado no √°udio) ou `translate` (que traduz o conte√∫do para o ingl√™s).

**Exemplo:**

```bash
whisper /caminho/do/seu/arquivo.mp4 --model turbo --task transcribe
```

---

**`--language`**: Este argumento permite que voc√™ **especifique o idioma falado no √°udio ou v√≠deo**. Existem muitas op√ß√µes de idiomas dispon√≠veis. Se voc√™ n√£o informar esse argumento, o `whisper` √© inteligente o suficiente para detectar automaticamente o idioma do conte√∫do.

Forma curta (language code):

```python
["af", "am", "ar", "as", "az", "ba", "be", "bg", "bn", "bo", "br", "bs", "ca",
"cs", "cy", "da", "de", "el", "en", "es", "et", "eu", "fa", "fi", "fo", "fr",
"gl", "gu", "ha", "haw", "he", "hi", "hr", "ht", "hu", "hy", "id", "is", "it",
"ja", "jw", "ka", "kk", "km", "kn", "ko", "la", "lb", "ln", "lo", "lt", "lv",
"mg", "mi", "mk", "ml", "mn", "mr", "ms", "mt", "my", "ne", "nl", "nn", "no",
"oc", "pa", "pl", "ps", "pt", "ro", "ru", "sa", "sd", "si", "sk", "sl", "sn",
"so", "sq", "sr", "su", "sv", "sw", "ta", "te", "tg", "th", "tk", "tl", "tr",
"tt", "uk", "ur", "uz", "vi", "yi", "yo", "yue", "", "zh"]
```

- Exemplo para portugu√™s do Brasil: `--language pt`

Forma longa (language name):

```python
["Afrikaans", "Albanian", "Amharic", "Arabic", "Armenian", "Assamese",
"Azerbaijani", "Bashkir", "Basque", "Belarusian", "Bengali", "Bosnian",
"Breton", "Bulgarian", "Burmese", "Cantonese", "Castilian", "Catalan",
"Chinese", "Croatian", "Czech", "Danish", "Dutch", "English", "Estonian",
"Faroese", "Finnish", "Flemish", "French", "Galician", "Georgian", "German",
"Greek", "Gujarati", "Haitian", "Haitian Creole", "Hausa", "Hawaiian", "Hebrew",
"Hindi", "Hungarian", "Icelandic", "Indonesian", "Italian", "Japanese",
"Javanese", "Kannada", "Kazakh", "Khmer", "Korean", "Lao", "Latin", "Latvian",
"Letzeburgesch", "Lingala", "Lithuanian", "Luxembourgish", "Macedonian",
"Malagasy", "Malay", "Malayalam", "Maltese", "Mandarin", "Maori", "Marathi",
"Moldavian", "Moldovan", "Mongolian", "Myanmar", "Nepali", "Norwegian",
"Nynorsk", "Occitan", "Panjabi", "Pashto", "Persian", "Polish", "Portuguese",
"Punjabi", "Pushto", "Romanian", "Russian", "Sanskrit", "Serbian", "Shona",
"Sindhi", "Sinhala", "Sinhalese", "Slovak", "Slovenian", "Somali", "Spanish",
"Sundanese", "Swahili", "Swedish", "Tagalog", "Tajik", "Tamil", "Tatar",
"Telugu", "Thai", "Tibetan", "Turkish","Turkmen", "Ukrainian", "Urdu", "Uzbek",
"Valencian", "Vietnamese", "Welsh", "Yiddish", "Yoruba"]
```

- Exemplo para portugu√™s do Brasil: `--language Portuguese`

Se precisar de um dicion√°rio completo com todos os idiomas e seus c√≥digos, ele est√° dispon√≠vel em `whisper.tokenizer.LANGUAGES` dentro do c√≥digo do `whisper`.

**Exemplo:**

```bash
# Para o comando ficar menor, vou manter tudo padr√£o
# model turbo (padr√£o)
# task transcribe (padr√£o)
# etc...
# Idioma falado no v√≠deo "Portugu√™s"
whisper /caminho/do/seu/arquivo.mp4 --language pt
```

---

**`--temperature`:** controla a "criatividade" do modelo. Vai de `0.0` a `1.0`. Quanto mais alto, mais liberdade o modelo tem pra decidir os pr√≥ximos tokens. Esse par√¢metro interage com `--beam_size`, `--patience` e `--best_of`.

**`--beam_size`:** n√∫mero de hip√≥teses que o modelo mant√©m em paralelo. Pensa como se ele testasse v√°rios caminhos ao mesmo tempo e no fim escolhesse o melhor. O padr√£o √© `5` e **s√≥ funciona se `--temperature == 0.0`**.

**`--patience`:** fator de toler√¢ncia que faz o modelo continuar explorando novas hip√≥teses mesmo depois de achar uma aceit√°vel. Requer `--temperature == 0.0` e `--beam_size > 1`.

**`--best_of`:** n√∫mero de amostras diferentes geradas antes de escolher a melhor. Funciona apenas quando `--temperature > 0.0`.

**Cola r√°pida:**

```
- temperature > 0 ‚Üí usa sampling
  ‚úÖ --best_of 5 (5 amostras)
  üî¥ --beam_size (ignorado)
  üî¥ --patience (ignorado)

- temperature == 0 ‚Üí usa beam search
  ‚úÖ --beam_size 5 (5 hip√≥teses)
  ‚úÖ --patience 2 (2 x 5 = 10 hip√≥teses)
  üî¥ --best_of (ignorado)

- temperature == 0 ‚Üí greedy
  ‚úÖ --beam_size 1 (1 hip√≥tese)
  üî¥ --patience (n√£o faz diferen√ßa)
  üî¥ --best_of (ignorado)
```

**Importante:** Quanto maiores os valores de `--beam_size`, `--patience` e `--best_of`, mais lento e "indeciso" o modelo tende a ficar. Isso acontece porque ele precisa gerar mais hip√≥teses ou amostras e, em seguida, tomar uma decis√£o entre elas. Fa√ßa testes r√°pidos para confirmar esse comportamento.

**Observa√ß√£o sincera:**

Na pr√°tica, o modelo vai responder como foi treinado, independente do seu capricho nas configs. Trocar `temperature`, `beam_size`, `patience` e afins pode virar desperd√≠cio de tempo.

**Recomenda√ß√£o direta:** s√≥ mexa nessas op√ß√µes se:

- o modelo come√ßar a repetir palavras (loop)
- estiver errando demais em blocos grandes

Se for s√≥ por causa de uma ou duas palavras... aceita e segue. Ou ent√£o faz igual eu: **testa tudo por uma semana e conclui que o padr√£o j√° era bom** üòÖ

**Exemplo:**

O arquivo de sa√≠da ser√° `srt` (SubRip) na pasta indicada em `-o`. Essa pasta ser√° criada caso n√£o exista.

```bash
# Greedy: Mais r√°pido, mas pode errar mais por considerar apenas uma hip√≥tese por vez.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 1

# Beam Search: Utiliza 3 hip√≥teses em paralelo.
# O 'patience' padr√£o √© 1.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.0 --beam_size 3

# Sampling: Gera 5 amostras diferentes para escolher a melhor.
whisper /caminho/do/seu/arquivo.mp4 --temperature 0.7 --best_of 5
```

**`--temperature_increment_on_fallback`**: Este argumento permite que voc√™ **aumente a temperatura do modelo em casos de falha na transcri√ß√£o**. Se o modelo encontrar dificuldades na temperatura `0.0`, ele far√° um "fallback" e tentar√° com a temperatura incrementada. O valor tamb√©m varia de `0.0` a `1.0`. No entanto, **cuidado: definir `0.0` para este argumento causar√° um erro `ZeroDivisionError: float division by zero`** (isso pode ser um pequeno "bugzinho" ü´£, mas, de fato, n√£o faria muito sentido usar zero aqui, j√° que o objetivo √© justamente _incrementar_ a temperatura). O valor padr√£o √© `0.2`.

---

**`--max_line_width`**: Define a **quantidade m√°xima de caracteres por linha** na sua legenda. O valor padr√£o √© `1000` (um limite bastante alto, codificado diretamente na classe `SubtitlesWriter` do `whisper`). Eu, particularmente, costumo usar `45` para uma melhor legibilidade. **Importante:** Se este argumento for utilizado, ele anula o `--max_words_per_line`. **Requer `--word_timestamps True`**.

**`--max_line_count`**: Controla a **quantidade m√°xima de linhas por legenda** (ou "bloco" de texto). Eu uso o valor `2`, mas, nos meus testes, percebi que isso for√ßa todas as legendas a terem sempre duas linhas. Para mim, n√£o √© um problema, mas vale a pena voc√™ testar para ver como se adapta ao seu caso. **Requer `--word_timestamps True`**.

**`--max_words_per_line`**: Determina a **quantidade m√°xima de palavras por linha** na legenda. O padr√£o tamb√©m √© um valor alto, `1000` (tamb√©m "hardcoded" na classe `SubtitlesWriter`). Embora eu n√£o costume us√°-lo, acredito que `5` palavras por linha pode resultar em uma leitura mais confort√°vel. **Aten√ß√£o:** Ser√° anulado por `--max_line_width` caso voc√™ use ambos no mesmo comando. **Requer `--word_timestamps True`**.

**`--highlight_words`**: Este √© o argumento respons√°vel por criar o **efeito de "karaok√™"** na sua transcri√ß√£o. Ele faz com que cada palavra falada seja sublinhada no momento exato em que √© pronunciada. **Requer `--word_timestamps True`**.

**`--word_timestamps`**: Este argumento √© a **chave** para ativar os recursos de sincroniza√ß√£o detalhada. Ao defini-lo como `True`, o modelo passar√° a gerar **timestamps para cada palavra**, em vez de apenas por blocos de frase. Isso pode, sim, aumentar consideravelmente o tempo de transcri√ß√£o, mas √© um requisito fundamental para que v√°rios outros argumentos (como os de formata√ß√£o de linha e destaque de palavras) funcionem. O valor padr√£o √© `False`.

**Exemplo Completo de Transcri√ß√£o Detalhada**

Veja um exemplo de como combinar v√°rios desses argumentos para obter uma transcri√ß√£o formatada e com destaque de palavras:

```bash
# A '\' (barra invertida no final da linha) √© usada apenas para indicar que
# o comando continua na linha de baixo. Isso √© uma boa pr√°tica para evitar
# que o comando fique muito longo na horizontal e melhora a legibilidade.
whisper meu_video.mp4 \
  --model large-v2 \
  --language pt \
  --output_format srt \
  --word_timestamps True \
  --highlight_words True \
  --max_line_width 45 \
  --max_line_count 2
```

---

**`--initial_prompt`**:

Este √© um texto opcional que serve como um **"empurr√£ozinho" para o modelo antes que ele comece a transcrever**. Funciona como uma dica de estilo ou contexto. No entanto, √© importante notar que ele s√≥ influencia a **primeira "janela" do √°udio** (que por padr√£o tem 30 segundos).

**Exemplo Pr√°tico:**

Se o seu v√≠deo √© sobre programa√ß√£o, especificamente Python, voc√™ pode passar um prompt como este:

```bash
--initial_prompt "v√≠deo de uma explica√ß√£o sobre programa√ß√£o com destaque para bibliotecas do Python"
```

Isso pode ajudar o modelo a reconhecer e transcrever termos t√©cnicos de programa√ß√£o e Python com mais precis√£o. Mas, como dito, n√£o espere milagres para o v√≠deo inteiro; essa influ√™ncia √© apenas um toque inicial. Para as janelas seguintes, o modelo pode usar o texto transcrito anteriormente, se a op√ß√£o `--condition_on_previous_text` estiver como `True` (que √© o padr√£o).

**Analogia para Entender Melhor:**

> Imagine que √© como dizer para um cantor, antes de ele subir no palco:
> "Tem 300 mil pessoas te esperando, detona l√°!"
> Ele vai subir j√° no clima certo, mas o resto da performance depender√° do show em si. Da mesma forma, o modelo continua a transcri√ß√£o com base no que "ouviu" e transcreveu depois do prompt inicial.

---

**`--condition_on_previous_text`**:

Este argumento crucial define se **o texto que j√° foi transcrito ser√° usado como contexto** para ajudar a transcrever a pr√≥xima "janela" do √°udio.

- `True` (padr√£o): √â a configura√ß√£o ideal para a maioria dos casos. Ela ajuda a manter a **fluidez e a consist√™ncia** do texto, garantindo uma boa coes√£o entre os blocos da transcri√ß√£o.
- `False`: Desativa o uso do contexto anterior. Isso pode ser √∫til para **evitar "loops de erro"**, onde o modelo fica repetindo frases ou palavras indefinidamente.

> _Exemplo de Uso:_
> Se a transcri√ß√£o come√ßar a errar e ficar repetindo, por exemplo, `"Ol√°, pessoal, hoje vamos falar sobre..."` em loop, desativar este argumento (`--condition_on_previous_text=False`) pode quebrar esse ciclo vicioso.

---

**Recomenda√ß√µes Gerais para Contexto**

Para otimizar suas transcri√ß√µes, considere as seguintes dicas:

- Para v√≠deos **bem gravados**, com **√°udio limpo** e **sem erros ou repeti√ß√µes evidentes**, mantenha o padr√£o: `--condition_on_previous_text=True`.
- Se o modelo come√ßar a **repetir frases ou palavras** de forma indesejada, experimente mudar para `--condition_on_previous_text=False`.
- O `--initial_prompt` pode ajudar **somente no in√≠cio** da transcri√ß√£o. N√£o espere que ele resolva problemas de consist√™ncia para o v√≠deo inteiro, mas pode ser √∫til para guiar o modelo em termos espec√≠ficos.

---
